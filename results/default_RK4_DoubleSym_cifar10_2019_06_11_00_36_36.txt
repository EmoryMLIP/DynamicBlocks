device cuda:0
time steps Y:       [0, 1, 2, 3, 4]
time steps theta:   [0, 1, 2, 3, 4]
no. of channels:    [16, 32, 64, 64]
no. of epochs:      120
ODE reg param:      0.0
Use checkpointing:  False
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
Files already downloaded and verified
Files already downloaded and verified
training on 40000 images ; validating on 10000 images
Training  251866  weights in  78  layers
optimizer = SGD with momentum=9.0e-01, weight_decay=4.0e-04, nesterov=0, batchSize=125
epoch     time      |runMean|   |runVar|    lr        |params|    avgLoss   acc       valLoss   valAcc   
1         81.3      4.01e+00    1.13e+01    1.00e-01  1.20e+01    1.68e+00  37.43     1.77e+00  39.75    
2         81.4      2.26e+00    1.16e+00    1.00e-01  1.02e+01    1.29e+00  53.05     1.88e+00  39.89    
3         81.2      1.29e+00    5.12e-01    1.00e-01  8.94e+00    1.08e+00  61.24     1.79e+00  48.46    
4         81.2      1.21e+00    4.47e-01    1.00e-01  8.23e+00    9.79e-01  64.99     1.93e+00  47.54    
5         80.2      1.13e+00    5.44e-01    1.00e-01  8.10e+00    9.10e-01  67.41     1.54e+00  54.43    
6         80.9      1.57e+00    2.85e-01    1.00e-01  8.20e+00    8.54e-01  69.64     1.25e+00  58.08    
7         81.2      1.47e+00    3.37e-01    1.00e-01  8.31e+00    7.98e-01  72.00     1.40e+00  56.32    
8         81.0      1.39e+00    3.94e-01    1.00e-01  8.25e+00    7.53e-01  73.52     2.53e+00  40.00    
9         81.5      1.12e+00    2.53e-01    1.00e-01  8.37e+00    7.37e-01  74.40     2.12e+00  49.23    
10        81.0      1.24e+00    2.40e-01    1.00e-01  8.30e+00    6.95e-01  75.92     1.25e+00  58.90    
11        80.8      1.57e+00    3.01e-01    1.00e-01  8.31e+00    6.75e-01  76.51     1.20e+00  61.67    
12        81.1      1.44e+00    3.41e-01    1.00e-01  8.38e+00    6.55e-01  77.25     1.39e+00  61.13    
13        81.3      1.28e+00    3.48e-01    1.00e-01  8.37e+00    6.41e-01  77.85     1.63e+00  52.88    
14        81.4      1.35e+00    3.05e-01    1.00e-01  8.41e+00    6.24e-01  78.55     9.59e-01  67.18    
15        81.4      1.26e+00    2.61e-01    1.00e-01  8.54e+00    6.16e-01  78.56     1.43e+00  59.09    
16        81.3      1.37e+00    2.51e-01    1.00e-01  8.62e+00    6.10e-01  78.88     1.79e+00  56.17    
17        81.4      1.45e+00    2.45e-01    1.00e-01  8.61e+00    6.00e-01  79.49     1.41e+00  59.91    
18        80.9      1.52e+00    3.17e-01    1.00e-01  8.69e+00    5.93e-01  79.56     8.96e-01  70.41    
19        81.1      1.40e+00    1.97e-01    1.00e-01  8.57e+00    5.86e-01  79.67     1.43e+00  56.84    
20        81.1      1.56e+00    2.91e-01    1.00e-01  8.69e+00    5.78e-01  80.04     1.70e+00  52.18    
21        81.1      1.62e+00    2.84e-01    1.00e-01  8.80e+00    5.72e-01  80.28     1.27e+00  62.04    
22        81.1      1.46e+00    2.91e-01    1.00e-01  8.83e+00    5.68e-01  80.53     1.51e+00  58.77    
23        81.3      1.50e+00    3.28e-01    1.00e-01  8.87e+00    5.62e-01  80.60     1.48e+00  60.29    
24        81.1      1.39e+00    2.79e-01    1.00e-01  8.80e+00    5.60e-01  80.67     1.40e+00  57.79    
25        80.9      1.49e+00    2.68e-01    1.00e-01  8.78e+00    5.48e-01  81.19     1.51e+00  59.04    
26        81.4      1.59e+00    1.89e-01    1.00e-01  8.78e+00    5.48e-01  80.97     1.75e+00  56.00    
27        81.0      1.58e+00    1.88e-01    1.00e-01  8.87e+00    5.40e-01  81.32     1.42e+00  62.08    
28        81.2      1.33e+00    2.21e-01    1.00e-01  8.89e+00    5.41e-01  81.41     1.17e+00  64.33    
29        81.1      1.29e+00    1.79e-01    1.00e-01  8.98e+00    5.44e-01  81.25     7.93e-01  72.70    
30        81.5      1.33e+00    2.20e-01    1.00e-01  8.97e+00    5.35e-01  81.61     8.57e-01  71.78    
31        81.1      1.54e+00    2.10e-01    1.00e-01  8.97e+00    5.32e-01  81.77     1.25e+00  61.04    
32        80.8      1.51e+00    1.91e-01    1.00e-01  8.91e+00    5.28e-01  81.79     1.14e+00  64.05    
33        80.9      1.24e+00    2.00e-01    1.00e-01  9.02e+00    5.30e-01  81.77     1.18e+00  62.48    
34        80.7      1.30e+00    2.31e-01    1.00e-01  9.03e+00    5.29e-01  81.87     1.82e+00  52.72    
35        80.8      1.65e+00    1.99e-01    1.00e-01  8.91e+00    5.25e-01  82.04     1.11e+00  64.51    
36        80.8      1.54e+00    1.93e-01    1.00e-01  8.97e+00    5.11e-01  82.50     1.17e+00  63.89    
37        80.2      1.40e+00    2.08e-01    1.00e-01  9.05e+00    5.24e-01  82.03     1.32e+00  63.24    
38        80.7      1.60e+00    2.42e-01    1.00e-01  9.09e+00    5.19e-01  82.08     1.28e+00  66.75    
39        80.8      1.68e+00    2.85e-01    1.00e-01  9.17e+00    5.17e-01  82.05     1.22e+00  64.89    
40        80.7      1.27e+00    2.22e-01    1.00e-01  9.10e+00    5.15e-01  82.46     1.00e+00  70.43    
41        80.7      1.38e+00    1.69e-01    1.00e-01  9.14e+00    5.08e-01  82.51     1.05e+00  66.63    
42        81.3      1.53e+00    1.65e-01    1.00e-01  9.18e+00    5.15e-01  82.14     8.60e-01  71.01    
43        81.0      1.36e+00    2.85e-01    1.00e-01  9.16e+00    5.08e-01  82.41     1.91e+00  54.35    
44        80.8      1.56e+00    2.37e-01    1.00e-01  9.16e+00    5.06e-01  82.69     1.31e+00  63.01    
45        81.1      1.64e+00    2.07e-01    1.00e-01  9.24e+00    5.11e-01  82.52     1.23e+00  64.42    
46        81.3      1.46e+00    1.77e-01    1.00e-01  9.18e+00    5.13e-01  82.30     2.48e+00  49.32    
47        81.1      1.43e+00    2.16e-01    1.00e-01  9.19e+00    4.98e-01  82.91     1.70e+00  49.98    
48        81.0      1.40e+00    2.91e-01    1.00e-01  9.26e+00    5.02e-01  82.63     2.02e+00  54.94    
49        81.2      1.57e+00    2.80e-01    1.00e-01  9.28e+00    5.01e-01  82.74     1.09e+00  66.99    
50        81.1      1.43e+00    1.40e-01    1.00e-01  9.26e+00    5.00e-01  82.78     1.52e+00  56.58    
51        80.9      1.40e+00    1.55e-01    1.00e-01  9.21e+00    4.97e-01  82.93     1.96e+00  53.74    
52        81.1      1.42e+00    2.35e-01    1.00e-01  9.20e+00    5.04e-01  82.77     1.36e+00  64.37    
53        81.3      1.47e+00    2.15e-01    1.00e-01  9.23e+00    4.95e-01  83.03     1.20e+00  64.22    
54        81.2      1.57e+00    1.89e-01    1.00e-01  9.32e+00    4.98e-01  82.75     1.11e+00  67.47    
55        81.2      1.67e+00    2.12e-01    1.00e-01  9.36e+00    4.93e-01  83.11     9.78e-01  69.81    
56        80.9      1.40e+00    2.71e-01    1.00e-01  9.31e+00    4.95e-01  82.92     1.08e+00  67.40    
57        81.2      1.52e+00    2.28e-01    1.00e-01  9.30e+00    4.95e-01  82.97     8.79e-01  70.88    
58        81.2      1.38e+00    2.37e-01    1.00e-01  9.29e+00    4.93e-01  82.96     1.42e+00  58.73    
59        81.3      1.37e+00    1.94e-01    1.00e-01  9.42e+00    4.95e-01  82.82     1.17e+00  65.31    
60        81.5      1.40e+00    1.83e-01    1.00e-01  9.43e+00    4.91e-01  83.14     2.25e+00  46.26    
61        81.3      9.62e-01    1.67e-01    1.00e-02  2.04e+00    3.43e-01  88.39     3.88e-01  86.69    
62        81.5      5.20e-01    7.98e-02    1.00e-02  1.43e+00    2.96e-01  89.91     3.93e-01  86.70    
63        81.0      3.88e-01    7.69e-02    1.00e-02  1.33e+00    2.78e-01  90.68     3.64e-01  87.43    
64        80.8      3.53e-01    6.08e-02    1.00e-02  1.33e+00    2.66e-01  90.94     3.73e-01  87.69    
65        80.4      3.78e-01    7.48e-02    1.00e-02  1.33e+00    2.58e-01  91.16     3.57e-01  87.81    
66        80.3      4.01e-01    6.49e-02    1.00e-02  1.35e+00    2.50e-01  91.56     3.76e-01  87.39    
67        80.6      3.68e-01    6.52e-02    1.00e-02  1.35e+00    2.41e-01  91.89     3.70e-01  87.50    
68        80.6      3.21e-01    5.62e-02    1.00e-02  1.36e+00    2.34e-01  92.14     3.78e-01  87.69    
69        80.5      3.81e-01    5.07e-02    1.00e-02  1.40e+00    2.32e-01  92.04     3.88e-01  86.78    
70        80.7      3.83e-01    5.79e-02    1.00e-02  1.41e+00    2.27e-01  92.39     3.65e-01  87.58    
71        80.8      3.82e-01    5.20e-02    1.00e-02  1.43e+00    2.25e-01  92.42     4.11e-01  86.18    
72        80.8      3.05e-01    4.84e-02    1.00e-02  1.46e+00    2.18e-01  92.64     3.88e-01  86.95    
73        80.1      4.11e-01    4.47e-02    1.00e-02  1.49e+00    2.14e-01  92.78     4.34e-01  85.67    
74        80.9      4.39e-01    4.17e-02    1.00e-02  1.50e+00    2.13e-01  92.81     3.74e-01  87.51    
75        80.9      3.55e-01    5.35e-02    1.00e-02  1.53e+00    2.12e-01  92.72     4.18e-01  86.55    
76        81.1      2.86e-01    3.81e-02    1.00e-02  1.52e+00    2.06e-01  93.02     3.94e-01  87.01    
77        81.0      3.15e-01    4.60e-02    1.00e-02  1.56e+00    2.03e-01  93.15     3.64e-01  87.82    
78        81.4      3.22e-01    3.93e-02    1.00e-02  1.58e+00    2.01e-01  93.09     5.10e-01  84.12    
79        81.2      2.99e-01    4.52e-02    1.00e-02  1.62e+00    1.97e-01  93.35     3.94e-01  87.12    
80        81.0      3.20e-01    3.22e-02    1.00e-02  1.63e+00    1.96e-01  93.40     4.80e-01  85.09    
81        81.6      1.70e-01    1.64e-02    1.00e-03  3.06e-01    1.67e-01  94.61     3.24e-01  89.23    
82        81.2      7.54e-02    1.52e-02    1.00e-03  2.14e-01    1.56e-01  94.99     3.23e-01  89.25    
83        81.1      8.13e-02    9.73e-03    1.00e-03  2.00e-01    1.53e-01  95.14     3.18e-01  89.37    
84        81.4      8.62e-02    1.10e-02    1.00e-03  1.99e-01    1.49e-01  95.25     3.24e-01  89.32    
85        81.2      7.55e-02    1.92e-02    1.00e-03  1.95e-01    1.48e-01  95.19     3.18e-01  89.37    
86        81.6      7.07e-02    1.61e-02    1.00e-03  1.93e-01    1.45e-01  95.50     3.22e-01  89.22    
87        81.3      6.76e-02    1.19e-02    1.00e-03  1.93e-01    1.47e-01  95.24     3.17e-01  89.25    
88        81.4      7.02e-02    1.72e-02    1.00e-03  1.92e-01    1.45e-01  95.41     3.20e-01  89.30    
89        81.2      5.81e-02    1.90e-02    1.00e-03  1.90e-01    1.42e-01  95.49     3.19e-01  89.38    
90        81.2      6.40e-02    9.34e-03    1.00e-03  1.94e-01    1.42e-01  95.45     3.20e-01  89.43    
91        81.0      6.50e-02    1.32e-02    1.00e-03  1.94e-01    1.43e-01  95.43     3.18e-01  89.41    
92        81.1      6.72e-02    1.44e-02    1.00e-03  1.95e-01    1.40e-01  95.52     3.17e-01  89.42    
93        81.1      6.22e-02    1.20e-02    1.00e-03  1.89e-01    1.39e-01  95.56     3.20e-01  89.54    
94        81.0      7.47e-02    1.01e-02    1.00e-03  1.91e-01    1.38e-01  95.62     3.22e-01  89.49    
95        81.0      6.78e-02    1.28e-02    1.00e-03  1.93e-01    1.36e-01  95.69     3.21e-01  89.26    
96        81.2      6.32e-02    1.12e-02    1.00e-03  1.88e-01    1.33e-01  95.96     3.21e-01  89.54    
97        81.0      6.65e-02    1.54e-02    1.00e-03  1.93e-01    1.36e-01  95.70     3.24e-01  89.24    
98        81.1      5.62e-02    1.05e-02    1.00e-03  1.93e-01    1.34e-01  95.89     3.20e-01  89.36    
99        80.2      5.63e-02    1.57e-02    1.00e-03  1.93e-01    1.36e-01  95.62     3.24e-01  89.37    
100       81.0      6.01e-02    1.66e-02    1.00e-03  1.98e-01    1.36e-01  95.64     3.24e-01  89.43    
101       80.8      2.03e-02    6.12e-03    1.00e-04  2.85e-02    1.31e-01  95.94     3.18e-01  89.41    
102       81.4      2.13e-02    1.31e-02    1.00e-04  2.46e-02    1.32e-01  95.86     3.19e-01  89.36    
103       81.1      2.21e-02    1.82e-02    1.00e-04  2.27e-02    1.32e-01  95.82     3.21e-01  89.47    
104       81.2      1.35e-02    1.20e-02    1.00e-04  2.31e-02    1.30e-01  95.99     3.20e-01  89.39    
105       80.9      1.50e-02    1.17e-02    1.00e-04  2.23e-02    1.27e-01  96.14     3.18e-01  89.59    
106       81.1      1.52e-02    8.73e-03    1.00e-04  2.15e-02    1.29e-01  96.00     3.21e-01  89.38    
107       81.0      1.29e-02    1.21e-02    1.00e-04  2.20e-02    1.28e-01  95.98     3.20e-01  89.29    
108       81.0      1.74e-02    1.86e-02    1.00e-04  2.24e-02    1.31e-01  95.94     3.19e-01  89.46    
109       81.1      1.39e-02    8.17e-03    1.00e-04  2.13e-02    1.31e-01  95.73     3.18e-01  89.58    
110       81.0      1.95e-02    6.11e-03    1.00e-04  2.17e-02    1.28e-01  96.03     3.20e-01  89.36    
111       80.9      1.88e-02    9.17e-03    1.00e-04  2.13e-02    1.29e-01  96.02     3.20e-01  89.50    
112       81.1      1.30e-02    7.67e-03    1.00e-04  2.18e-02    1.28e-01  95.93     3.20e-01  89.39    
113       80.3      2.12e-02    5.70e-03    1.00e-04  2.15e-02    1.28e-01  95.92     3.18e-01  89.51    
114       81.3      1.39e-02    9.26e-03    1.00e-04  2.16e-02    1.28e-01  96.09     3.18e-01  89.50    
115       81.3      1.78e-02    7.67e-03    1.00e-04  2.11e-02    1.27e-01  96.05     3.18e-01  89.48    
116       81.0      1.44e-02    9.39e-03    1.00e-04  2.11e-02    1.26e-01  96.17     3.24e-01  89.36    
117       81.1      2.74e-02    1.12e-02    1.00e-04  2.07e-02    1.27e-01  96.18     3.17e-01  89.47    
118       81.0      2.10e-02    9.89e-03    1.00e-04  2.16e-02    1.29e-01  95.90     3.19e-01  89.47    
119       81.0      1.36e-02    8.15e-03    1.00e-04  2.14e-02    1.28e-01  96.02     3.19e-01  89.58    
120       81.6      2.02e-02    1.23e-02    1.00e-04  2.11e-02    1.26e-01  96.12     3.20e-01  89.48    
Time elapsed:  9804.232657432556
Training complete. Now testing...

testing loss: 3.32e-01     testing accuracy: 89.08    
RKNet(
  (dynamicBlocks): ModuleList(
    (0): rk4(
      (controlLayers): ModuleList(
        (0): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (1): rk4(
      (controlLayers): ModuleList(
        (0): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (2): rk4(
      (controlLayers): ModuleList(
        (0): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
  (connectors): ModuleList(
    (0): ConnectingLayer(
      (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
      (act): ReLU()
      (normLayer): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ConnectingLayer(
      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (act): ReLU()
      (normLayer): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ConnectingLayer(
      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (act): ReLU()
      (normLayer): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (open): ConnectingLayer(
    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (act): ReLU()
    (normLayer): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
